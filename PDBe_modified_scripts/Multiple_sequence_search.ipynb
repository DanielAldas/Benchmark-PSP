{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint # used for pretty printing\n",
    "import requests # used to get data from the a URL\n",
    "import pandas as pd # used to analyse the results\n",
    "from modlamp.descriptors import PeptideDescriptor, GlobalDescriptor \n",
    "search_url = \"https://www.ebi.ac.uk/pdbe/search/pdb/select?\" # the rest of the URL used for PDBe's search API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw=pd.read_csv('grampa_AA.csv', index_col=0)\n",
    "#Erase sequences with unusual modifications\n",
    "data_raw=data_raw[data_raw[\"has_unusual_modification\"]==False]\n",
    "# Drop irrelevant columns\n",
    "datos_raw=data_raw.drop(['url_source','datasource_has_modifications','database','has_unusual_modification'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6169"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_raw=datos_raw[\"sequence\"]\n",
    "\n",
    "sec_0=[]\n",
    "[sec_0.append(x) for x in sec_raw if x not in sec_0]\n",
    "len(sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista con las secuencias del DF para poder trabajarla en modlAMP \n",
    "sec_raw=pd.Series.tolist(data_raw[\"sequence\"])\n",
    "#Calcular la longitud de las secuencias\n",
    "globaldesc=GlobalDescriptor(sec_raw)\n",
    "globaldesc.length()\n",
    "lon=globaldesc.descriptor\n",
    "data_raw[\"sequence_length\"]=lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=data_raw[(data_raw[\"sequence_length\"]>=10)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5638"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_prueba=test_data[\"sequence\"]\n",
    "sec_1=[]\n",
    "[sec_1.append(x) for x in sec_prueba if x not in sec_1]\n",
    "len(sec_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define some functions which will use to get the data from PDBe's search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request_post(search_dict, number_of_rows=10):\n",
    "    \"\"\"\n",
    "    makes a post request to the PDBe API\n",
    "    :param dict search_dict: the terms used to search\n",
    "    :param number_of_rows: number or rows to return - initially limited to 10\n",
    "    :return dict: response JSON\n",
    "    \"\"\"\n",
    "    # make sure we get the number of rows we need\n",
    "    if 'rows' not in search_dict:\n",
    "        search_dict['rows'] = number_of_rows\n",
    "    # set the return type to JSON\n",
    "    search_dict['wt'] = 'json'\n",
    "\n",
    "    # do the query\n",
    "    response = requests.post(search_url, data=search_dict)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"[No data retrieved - %s] %s\" % (response.status_code, response.text))\n",
    "\n",
    "    return {}\n",
    "\n",
    "def format_sequence_search_terms(sequence, filter_terms=None):\n",
    "    \"\"\"\n",
    "    Format parameters for a sequence search\n",
    "    :param str sequence: one letter sequence\n",
    "    :param lst filter_terms: Terms to filter the results by\n",
    "    :return str: search string\n",
    "    \"\"\"\n",
    "    # first we set the parameters which we will pass to PDBe's search\n",
    "    params = {\n",
    "        'json.nl': 'map',\n",
    "        'start': '0',\n",
    "        'sort': 'fasta(e_value) asc',\n",
    "        'xjoin_fasta': 'true',\n",
    "        'bf': 'fasta(percentIdentity)',\n",
    "        'xjoin_fasta.external.expupperlim': '0.1',\n",
    "        'xjoin_fasta.external.sequence': sequence,\n",
    "        'q': '*:*',\n",
    "        'fq': '{!xjoin}xjoin_fasta'\n",
    "    }\n",
    "    # we make sure that we add required filter terms if they aren't present\n",
    "    if filter_terms:\n",
    "        for term in ['pdb_id', 'entity_id', 'entry_entity', 'chain_id']:\n",
    "            filter_terms.append(term)\n",
    "        filter_terms = list(set(filter_terms))\n",
    "        params['fl'] = ','.join(filter_terms)\n",
    "\n",
    "    # returns the parameter dictionary\n",
    "    return params\n",
    "\n",
    "\n",
    "def run_sequence_search(sequence, filter_terms=None, number_of_rows=10):\n",
    "    \"\"\"\n",
    "    Runs a sequence search and results the results\n",
    "    :param str sequence: sequence in one letter code\n",
    "    :param lst filter_terms: terms to filter the results by\n",
    "    :param int number_of_rows: number of results to return\n",
    "    :return lst: List of results\n",
    "    \"\"\"\n",
    "    search_dict = format_sequence_search_terms(sequence=sequence, filter_terms=filter_terms)\n",
    "    response = make_request_post(search_dict=search_dict, number_of_rows=number_of_rows)\n",
    "    results = response.get('response', {}).get('docs', [])\n",
    "    print('Number of results {}'.format(len(results)))\n",
    "\n",
    "    # we now have to go through the FASTA results and join them with the main results\n",
    "\n",
    "    raw_fasta_results = response.get('xjoin_fasta').get('external')\n",
    "    fasta_results = {} # results from FASTA will be stored here - key'd by PDB ID and Chain ID\n",
    "\n",
    "    # go through each FASTA result and get the E value, percentage identity and sequence from the result\n",
    "\n",
    "    for fasta_row in raw_fasta_results:\n",
    "        # join_id = fasta_row.get('joinId')\n",
    "        fasta_doc = fasta_row.get('doc', {})\n",
    "        percent_identity = fasta_doc.get('percent_identity')\n",
    "        e_value = fasta_doc.get('e_value')\n",
    "        return_sequence = fasta_row.get('return_sequence_string')\n",
    "        pdb_id_chain = fasta_doc.get('pdb_id_chain').split('_')\n",
    "        pdb_id = pdb_id_chain[0].lower()\n",
    "        chain_id = pdb_id_chain[-1]\n",
    "        join_id = '{}_{}'.format(pdb_id, chain_id)\n",
    "        fasta_results[join_id] = {'e_value': e_value,\n",
    "                                  'percentage_identity': percent_identity,\n",
    "                                  'return_sequence': return_sequence}\n",
    "\n",
    "    # now we go through the main results and add the FASTA results\n",
    "    ret = [] # final results will be stored here.\n",
    "    for row in results:\n",
    "        pdb_id = row.get('pdb_id').lower()\n",
    "        chain_ids = row.get('chain_id')\n",
    "        for chain_id in chain_ids:\n",
    "            search_id = '{}_{}'.format(pdb_id, chain_id)\n",
    "            entry_fasta_results = fasta_results.get(search_id, {})\n",
    "            # we will only keep results that match the search ID\n",
    "            if entry_fasta_results:\n",
    "                row['e_value'] = entry_fasta_results.get('e_value')\n",
    "                row['percentage_identity'] = entry_fasta_results.get('percentage_identity')\n",
    "                row['result_sequence'] = entry_fasta_results.get('return_sequence_string')\n",
    "\n",
    "                ret.append(row)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def multiple_sequence_search(sequences):\n",
    "    \"\"\"\n",
    "    Performs sequence search for multiple entries\n",
    "    :param lst sequences: a list coontaining all the query sequences\n",
    "    \"\"\"\n",
    "    results=dict.fromkeys(sequences)\n",
    "    i=0\n",
    "    while i < len(sequences):\n",
    "        for values in results:\n",
    "            results[values]=run_sequence_search(sequences[i], filter_terms=['pdb_id', 'molecule_name'])\n",
    "            i=i+1\n",
    "            print(str(i)+\" sequences of \"+str(len(sequences)))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_dict(results):\n",
    "    \"\"\"\n",
    "    Delete sequences with no matches inside results dictionary\n",
    "    :param dict results: Dictionary containing all the results from multiple sequence search\n",
    "    \"\"\"\n",
    "    new_dict = {k: v for k, v in results.items() if len(v) != 0 }\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = multiple_sequence_search(sec_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_res = results_to_dict(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
